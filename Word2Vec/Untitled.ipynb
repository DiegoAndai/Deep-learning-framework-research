{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim Word2Vec example\n",
    "\n",
    "from : https://rare-technologies.com/word2vec-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SentenceReader:\n",
    "    \n",
    "    def __init__(self, dir_name, file_names = None):\n",
    "        self.dir_name = dir_name\n",
    "        self.file_names = file_names\n",
    "    \n",
    "    def __iter__(self):\n",
    "        if self.file_names:\n",
    "            for file_name in self.file_names:\n",
    "                with open(\"{}/{}\".format(self.dir_name,file_name), \"r\") as file:\n",
    "                    for line in file:\n",
    "                        quote = line.split(\"+++$+++\")[-1]\n",
    "                        yield self.parse_line(quote)\n",
    "        else:\n",
    "            for file_name in os.listdir(self.dir_name):\n",
    "                if \".\" != file_name[0]:\n",
    "                    with open(os.path.join(self.dir_name, file_name)) as file:\n",
    "                        for line in file:\n",
    "                            quote = line.split(\"+++$+++\")[-1]\n",
    "                            yield self.parse_line(quote)\n",
    "                            \n",
    "    def parse_line(self, line):\n",
    "        line = line.lower()\n",
    "        words = line.split()\n",
    "        clean = [self.parse_word(word) for word in words]\n",
    "        return clean\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_word(word):\n",
    "        return \"\".join(ch for ch in word if ch in string.ascii_lowercase)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reader = SentenceReader(\"cornell movie-dialogs corpus\", [\"utf-8_movie_lines.txt\"])\n",
    "# corpus at: http://www.mpi-sws.org/~cristian/Cornell_Movie-Dialogs_Corpus.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(iter = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.build_vocab(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11451210"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.17159574, -1.38211524, -0.65839279,  0.66371918,  0.25008303,\n",
       "       -0.87137908,  0.46099725, -0.40143147,  0.42487606,  0.67892998,\n",
       "       -0.47953248, -0.57823902,  0.89605874,  1.28453493, -2.19975948,\n",
       "        1.50941861, -0.73519313,  1.4789629 , -0.0514161 ,  0.17376542,\n",
       "       -0.77308714,  1.57945395, -0.62382013,  0.45165995,  0.27362987,\n",
       "        0.20029201,  0.10952923,  0.33495393, -1.5909481 , -0.74223483,\n",
       "       -0.21992083,  0.66005391, -0.15553699,  1.2604543 , -1.928038  ,\n",
       "        2.13802052, -0.12578124,  0.64992714,  0.70353693,  0.26033747,\n",
       "        0.93664891, -0.77797729, -1.19883513, -0.873191  ,  0.57891065,\n",
       "       -1.00570858, -0.21571285, -0.19170851,  0.97861749, -0.38185877,\n",
       "       -1.48081958, -0.86015868,  0.75768232,  0.77532715,  0.24341521,\n",
       "        0.2304181 ,  3.11559248,  0.24336527, -0.5964914 ,  0.1098717 ,\n",
       "        0.60708249, -0.58356047, -0.94773459,  0.81611025,  0.73523206,\n",
       "       -1.11317515, -0.07464366, -0.10873374, -0.54244339,  0.08619022,\n",
       "        0.30190632, -0.52923369,  0.89023358, -2.55780149, -0.61670172,\n",
       "        0.51078951, -0.1216246 , -2.39894509, -0.12432504, -1.01441026,\n",
       "        1.38231134, -1.21169007,  0.49076444, -1.26994729,  0.55885601,\n",
       "       -1.15295327,  1.87288821, -0.39630404, -0.6213159 , -0.62883097,\n",
       "        0.78756118,  0.70175636,  0.71437573,  0.23392259,  0.56958282,\n",
       "       -0.48748559, -0.91081107,  0.74589401,  0.03302629,  2.49309397], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"god\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Vectors = np.asarray([model[key] for key in model.vocab.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "viceroy\n",
      "ally\n",
      "cycle\n",
      "foremost\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for key in model.vocab.keys():\n",
    "    print(key)\n",
    "    i += 1\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tsne_rep = TSNE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_qty = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding = tsne_rep.fit_transform(Vectors[0: words_qty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding_x = [v[0] for v in embedding]\n",
    "embedding_y = [v[1] for v in embedding]\n",
    "embedding_labels = [key for key in model.vocab.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.xlim(min(embedding_x) , max(embedding_x))\n",
    "plt.ylim(min(embedding_y) , max(embedding_y))\n",
    "\n",
    "plt.scatter(embedding_x, embedding_y, marker = \"\")\n",
    "for i, tag in enumerate(embedding_labels[0: words_qty]):\n",
    "    plt.annotate(tag, (embedding_x[i], embedding_y[i]), size = 0.1)\n",
    "\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 250\n",
    "fig_size[1] = 100\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.margins(0.01,0)\n",
    "\n",
    "\n",
    "plt.savefig(\"movie quotes word embedding 10,000\", dpi = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.xlim(min(embedding_x) , max(embedding_x))\n",
    "plt.ylim(min(embedding_y) , max(embedding_y))\n",
    "\n",
    "plt.scatter(embedding_x, embedding_y, marker = \"\")\n",
    "for i, tag in enumerate(embedding_labels[0: 5000]):\n",
    "    plt.annotate(tag, (embedding_x[i], embedding_y[i]), size = 0.1)\n",
    "\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 250\n",
    "fig_size[1] = 100\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.margins(0.01,0)\n",
    "\n",
    "\n",
    "plt.savefig(\"movie quotes word embedding 5,000\", dpi = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.xlim(min(embedding_x) , max(embedding_x))\n",
    "plt.ylim(min(embedding_y) , max(embedding_y))\n",
    "\n",
    "plt.scatter(embedding_x, embedding_y, marker = \"\")\n",
    "for i, tag in enumerate(embedding_labels[0: 1000]):\n",
    "    plt.annotate(tag, (embedding_x[i], embedding_y[i]), size = 0.1)\n",
    "\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 250\n",
    "fig_size[1] = 100\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.margins(0.01,0)\n",
    "\n",
    "\n",
    "plt.savefig(\"movie quotes word embedding 1,000\", dpi = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
