{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim Word2Vec example\n",
    "\n",
    "from : https://rare-technologies.com/word2vec-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SentenceReader:\n",
    "    \n",
    "    def __init__(self, dir_name, file_names = None):\n",
    "        self.dir_name = dir_name\n",
    "        self.file_names = file_names\n",
    "    \n",
    "    def __iter__(self):\n",
    "        if self.file_names:\n",
    "            for file_name in self.file_names:\n",
    "                print(file_name)\n",
    "                with open(\"{}/{}\".format(self.dir_name,file_name), \"r\") as file:\n",
    "                    i = 0\n",
    "                    for line in file:\n",
    "                        if i % 1000000 == 0:\n",
    "                            print(\".\", end = \"\")\n",
    "                        if i == 5000000:\n",
    "                            raise StopIteration\n",
    "                        yield self.parse_line(line)\n",
    "                        i += 1\n",
    "                    print(\"\\n\")\n",
    "        else:\n",
    "            for file_name in os.listdir(self.dir_name):\n",
    "                if \".\" != file_name[0]:\n",
    "                    with open(os.path.join(self.dir_name, file_name)) as file:\n",
    "                        for line in file:\n",
    "                            yield self.parse_line(line)\n",
    "                            \n",
    "    def parse_line(self, line):\n",
    "        line = line.lower()\n",
    "        words = line.split()\n",
    "        clean = [self.parse_word(word) for word in words]\n",
    "        return clean\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_word(word):\n",
    "        return \"\".join(ch for ch in word if ch in string.ascii_lowercase)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reader1 = SentenceReader(\"Sentences\", [\"utf-8_movie_quotes.txt\", \"utf-8_supreme_court_quotes.txt\", \"utf-8_congress1.txt\"])\n",
    "# corpus at: http://www.mpi-sws.org/~cristian/Cornell_Movie-Dialogs_Corpus.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(iter = 2, min_count = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utf-8_movie_quotes.txt\n",
      ".\n",
      "\n",
      "utf-8_supreme_court_quotes.txt\n",
      ".\n",
      "\n",
      "utf-8_congress1.txt\n",
      "......"
     ]
    }
   ],
   "source": [
    "model.build_vocab(reader1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utf-8_movie_quotes.txt\n",
      ".\n",
      "\n",
      "utf-8_supreme_court_quotes.txt\n",
      ".\n",
      "\n",
      "utf-8_congress1.txt\n",
      "......utf-8_movie_quotes.txt\n",
      ".\n",
      "\n",
      "utf-8_supreme_court_quotes.txt\n",
      ".\n",
      "\n",
      "utf-8_congress1.txt\n",
      "......"
     ]
    },
    {
     "data": {
      "text/plain": [
       "172918209"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(reader1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.45946646,  1.74204123,  2.08415318,  3.52995658, -2.45585394,\n",
       "        1.5413512 , -1.34915471, -0.32728785,  1.30443788, -1.84741306,\n",
       "       -1.40759993, -0.62682223, -0.51812202, -2.85968113,  3.78868079,\n",
       "       -0.24303038,  0.42511192,  0.62268603, -2.61488843, -2.01616597,\n",
       "        3.9499526 ,  1.76219869, -2.41688704, -0.21294375,  0.58989346,\n",
       "        2.73736143, -0.12912902, -6.74059296,  1.19471288,  3.59105897,\n",
       "        2.61028314, -2.77319026, -0.85091722,  1.19799924,  2.93369222,\n",
       "        1.40380621,  0.93731457, -0.54000568,  0.50826752,  1.8099215 ,\n",
       "       -4.21683359, -1.70523465, -8.06800652, -1.85582972,  2.07072902,\n",
       "        0.83078301,  1.45601261, -1.38770604,  2.18412066, -0.46504655,\n",
       "       -2.65539408,  2.17604017,  1.3139751 , -2.26392579,  0.68120408,\n",
       "        1.85080278,  1.44322467,  0.7653352 ,  0.75531322,  1.7513535 ,\n",
       "       -1.18536985,  7.03028584, -0.25995138,  2.64513445, -5.00492716,\n",
       "       -2.22460008,  0.18032372,  0.08367028,  0.64354825, -1.09771633,\n",
       "        4.83222103, -2.20716143, -0.43342325,  5.15547848, -2.81676865,\n",
       "       -3.99197817, -1.44206691, -0.62037426, -1.38937211, -4.09553528,\n",
       "        4.24519205,  0.38971162,  0.47815502,  1.04852664,  0.53641027,\n",
       "       -0.7050944 ,  0.97708714,  2.5433476 , -1.40138924,  3.37029409,\n",
       "       -1.84298098, -1.4510957 ,  2.37739778, -2.6331625 , -5.86601973,\n",
       "        1.5108645 , -0.77399361, -1.0750345 , -0.81156874, -1.91525495], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"god\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keys = model.vocab.keys()\n",
    "Vectors = np.asarray([model[key] for key in keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "backdrop\n",
      "periods\n",
      "dil\n",
      "delegates\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for key in keys:\n",
    "    print(key)\n",
    "    i += 1\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tsne_rep = TSNE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_qty = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding = tsne_rep.fit_transform(Vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding_x = [v[0] for v in embedding]\n",
    "embedding_y = [v[1] for v in embedding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.xlim(min(embedding_x) , max(embedding_x))\n",
    "plt.ylim(min(embedding_y) , max(embedding_y))\n",
    "\n",
    "plt.scatter(embedding_x, embedding_y, marker = \"\")\n",
    "for i, tag in enumerate(list(keys)[0: words_qty]):\n",
    "    plt.annotate(tag, (embedding_x[i], embedding_y[i]), size = 0.1)\n",
    "\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 250\n",
    "fig_size[1] = 100\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.margins(0.01,0)\n",
    "\n",
    "\n",
    "plt.savefig(\"3 datasets word embedding 10,000\", dpi = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.xlim(min(embedding_x) , max(embedding_x))\n",
    "plt.ylim(min(embedding_y) , max(embedding_y))\n",
    "\n",
    "plt.scatter(embedding_x, embedding_y, marker = \"\")\n",
    "for i, tag in enumerate(list(keys)[0: 5000]):\n",
    "    plt.annotate(tag, (embedding_x[i], embedding_y[i]), size = 0.1)\n",
    "\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 250\n",
    "fig_size[1] = 100\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.margins(0.01,0)\n",
    "\n",
    "\n",
    "plt.savefig(\"3 datasets word embedding 5,000\", dpi = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.xlim(min(embedding_x) , max(embedding_x))\n",
    "plt.ylim(min(embedding_y) , max(embedding_y))\n",
    "\n",
    "plt.scatter(embedding_x, embedding_y, marker = \"\")\n",
    "for i, tag in enumerate(list(keys)[0: 1000]):\n",
    "    plt.annotate(tag, (embedding_x[i], embedding_y[i]), size = 0.1)\n",
    "\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 250\n",
    "fig_size[1] = 100\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.margins(0.01,0)\n",
    "\n",
    "\n",
    "plt.savefig(\"3 datasets word embedding 1,000\", dpi = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.xlim(min(embedding_x) , max(embedding_x))\n",
    "plt.ylim(min(embedding_y) , max(embedding_y))\n",
    "\n",
    "plt.scatter(embedding_x, embedding_y, marker = \"\")\n",
    "for i, tag in enumerate(list(keys)[0: 2500]):\n",
    "    plt.annotate(tag, (embedding_x[i], embedding_y[i]), size = 0.1)\n",
    "\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 250\n",
    "fig_size[1] = 100\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.margins(0.01,0)\n",
    "\n",
    "\n",
    "plt.savefig(\"3 datasets word embedding 2,500\", dpi = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"queen\" in model.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10486, 6621, 6800, 11945]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = [\"man\", \"woman\", \"king\", \"queen\"]\n",
    "indices = list(map(list(keys).index, search))\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "for i, j in enumerate(indices):\n",
    "    print(i, j)\n",
    "    plt.annotate(search[i], (embedding_x[j], embedding_y[j]), size = 0.1)\n",
    "plt.savefig(\"man-woman vector\", dpi = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('silence', 0.5810280442237854)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
